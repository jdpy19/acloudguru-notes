SQS - Simple Queue Service
  What is SQS?
    A message queue service.
    Enables web service applications to quickly and reliably queue messages that  one component in the application generates for another component to consume.
    A queue is a temporary repository for messages awaiting processing.

  Examples
    1. Meme website: Upload an image, store photo in S3, trigger lambda function sends data to SQS, EC2 pull SQS for tasks to complete, upload completed meme in S3.

    If you lose an EC2 image before it has completed, you won't lose the job because it will still be in the queue. 

    2. Travel Website: Searching for flights, EC2 (web server) sends data to SQS, EC2 (app server) pulls sqs for search jobs.

    SQS is used for pull based services, SNS is used for push based services.

    Jobs are not lost because of the visibility timeout, when a job is pulled it is marked as invisible. If the job has not been completed by the timeout, it will reappear.

    We remove dependency between two parts of the architecture, this is called decoupling your infrastructure.

  SQS features
    1. Decouple Application Components
      Deouple the components of an application so they run independently, easing message management between components.
    2. Store Messages
      Any component of a dsitributed application can store messages in the queue. Messages can contain up to 256 KB of text in any format.
    3. Retrieve Messages
      AAny componeent can later retrieve the messages programmatically using the Amazon SQS API.

  A Buffer Between Componenets
    A buffer between the compoenent receiving the data for processing, and the componeent producing and saving the data.

  Resolves scheduling issues
    The queue resolves issues that arise if the producer is producing work faster than the consumer can process it, or if the producer or consumer are only intermitteently connected to the network.

  SQS Key Facts
    Pull-Based, not push based.
    Messages are 256 KB in size.
    Text data: XML, JSON, and unformatted.
    Guaranteee: Messages will be processed at least once.
    Up to 14 days: Messages can be kept in the queue from one minute to 14 days. Default is 4 days

  Exam tips
    Distributed message queueing system
    Allows us to decouple the componenets of an application so that they are independent.
    Pull-based, not push-based.

  Understanding SQS Queue Types
    What types are available?
      Standard Queues (Default): Best-effort Ordering
        Unlimited Transactions: Nearly-Unlimited number of transactions per second
        Guarantee: Guarantees that a message is delivered at least once.
        Best-Effort Ordering: Standard queues provide best-effort ordering which ensures that messages are generally delivered in the same order as they are sent.
        Occasionally (because of the highlly-distributed architecture that allows high throughput), more than one copy of a message might be delivered out of order.
      FIFO: First in, first out: Order is strictly preserved
        First-in-first-out Delivery: THe order in which messages are sent and received is strictly preserved.
        Exactly-Once Processing: A message is delivered once and remains available until a consumer processes and deletes it. Duplicates are not introduced.\
        300 TPS Limit: FIFO queues are limted to 300 transactions per second, but have all the capabilities of standard queues.
        Great for banking applications.

    Exam Tips:
      Standard
        Best-effort ordering
        Message delivered at least once.
        Occasional Duplicates
        Default
      FIFO
        First-in-first-out message order is strictly preserved.
        Messages are delivered once
        No Duplicates
        Good for banking transactions which need to happen in a strict order.

  SQS Settings
    Visibility Timeout (30s default): The amount of time that the message is invisible in the SQS queue after a reader picks upt that message.
      Ideally, the job will be processed before the visibilty time out expires, and the message will then be deleted from the queue.
      However, if the job is not processed within that time. The message will become visible again and another reader will process it. (Opportunity for duplicates)
      Increase the visibility fi needed, maximum is 12 hours. 
    Short Polling vs Long Polling
      Short Polling: Returns a response immediately even if the message queue being polled is empty
        This can result ina  lot of empty responses if nothing is in the queue.
        You will still pay for these responses
      Long Polling: Periodically polls the queue
        Doesn't return a response until a message arrivs in the message queue or the long poll times out
        Can save money!
        Long polling is generally preferable to short polling.

    Exam Tips
      Visibility Timeout
      Short Polling: A response is returned immediately even if no messages are in the queue. A cost per response.
      Long Polling: Periodically polls the queue and only returns a response when a message is in the queue or the timeout is reached. Most effective option.

  SQS Delay Queues & Managing Large Messages
    SQS Delay Queues - postpone delivery of new messages
      Postpone dleivery of new messages to a queue for a number of seconds
      Message sent to the delay queue remain invisible to consumers for the duration of the delay period.
      Default delay is 0 seconds, maximum is 900
      For standard queues, changing the setting doesn't affect the dealy of messages already in the queue, only new messages.
      For FIFO queues, this affects the delay of messages already in the queue.

      When should you use a delay queue?
        Large distributed applications which may need to introduce a delay in processing.
        You need to apply a delay to an entire queue of messages.
        Adding a delay of a few seconds to allow for updates to your sales and stock control databases before sending a notification to a consumer confirming an online transaction

    Managing Large SQS Messages
      Best Practive for Managing Large SQS Messages Using S3  
        For large SQS messages - 256KB up to 2GB in size
        Use S3 to store the messages
        Use Amazon SQS Extended Client Library for Java to manage them
        You'll also need the AWS SDK for Java - provides an API for S3 bucket and object operations

        Amazon SQS Extended Client Library for Java
          Specify that messages are always stored in Amazon S3 OR only messages > 256KB
          Send a message which references a message object stored in S3
          Get a message object from S3
          Delete a message object from S3

      You need:
        AWS SDK for Java
        SQS Extended Client Library for Java
        An S3 bucket

      Can't Use:
        AWS CLI
        AWS Management Console / SQS Console
        SQS API
        Any other AWS SDK

  Exam Tips
    SQS Delay Queue
      Postpone delivery of new messages
      Messages in Delay Queue remain invisible for the duration of the delay period (0-900s)
      Large distributed applications which may need to introduce a delay in processing
    Managine Large Messages
      Store large messges in S3
      AWS SDK for JavaAmazon SQS Extended Client Library for Javas

SNS - Simple Notification Services
  SNS - A web service that makes it easy to set up, operate, and send notifications from the Cloud.
  Messages sent from an application can be immeditately delivered to subscribers or other applications.

  A notifications service.

  Push Notifications: To devices (Apple, Google, Fire OS, Windows, Android)
  SMS and Email: SMS Text message or email to Amazon Simple Quue Service (SQS) or any HTTP endpoint
  Lambda: Trigger Lambda functions to process the infromation in the message, publish to another SNS topic, or send the message to another AWS service.

  How does it work?
    A pub-sub model. Publish and Subscribe.
      Applications PUBLISH or PUSH messages to a topic
      Subscribers RECEIVE messages from a topic

    A Pub-Sub Model 
      Application -> SNS -> Topic -> Subscribers

    Notifications are delivered using a push mechanism that eliminates the need to periodically check or poll for new information and updates

  What is a topic?
    It's an access point, allowing recipients to subscribe to, and receive identical copies of the same notification. SNS delivers appropriately-formatted copies of the message to each subscriber. 

  What about durability?
    Durable storage: Prevents messages from being lost
    All messages published to Amazon SNS are stored redundantly across multiple Availability Zones.

  SNS Benefits
    Instantaneous: Instaneous, push-based delivery (no polling)
    Simple: Simple APIs and easy integration with applications
    Flexible: Flexible message delivery over multiple transport protocols.
    Inexpensive: Inexpensive, pay as you go model with no up-front costs
    Easy to Configure: Web-based AWS Management Console offers the simplicity of a point-and-click interface
    Managed Service: With all the high availability and durability features needed for a production environment

  Selecting the right Solution:
    You might be asked to select the right solution for a given scenario: SNS vs SQS

    SNS
      Messaging service
      SNS is push based
      Think push notifications
    SQS
      Messaging service, held in a queue instead of being delivered.
      SQS is pull based
      Think polling the queue for messages.

  SNS Exam Tips
    Notificaitons: Scalable and highlly available notfication service which allows us ot send push notifications from the cloud.
    Message formats: Sms text message, email. Amazon SQS, or any HTTP endpoint.
    Pub-Sub: Push notification vs pull or poll mechanism
    Push = SNS
    Pull = SQS

  SES vs SNS
    Amazon SES (Simple Email Service)
      Scalable and Highly Available Email
        Designed to hel pmarketing teams and application developers send marketing, notification, and transactional emails to their customers using a pay-as-you-go model.
        Send and Receive Email: Can also be used to receive emails with incoming mails delivered to an S3 bucket.
        Trigger Lambda and SNS

      Use Cases:
        Automated Emails: Notification that htere is a new post in a discussion forum that you moderate.
        Online Purchases: Purchase confirmations, shipping notifications, and order status updates
        Marketing Emails: Marketing communications, advertisements, newsletters, special offers, etcs

  SES: 
    Email only
    Can trigger a Lambda funciton or SNS notification
    Can be used for both incoming and outgoing email
    An email address is all that is required to start sending messages.

  SNS
    Pub/sub messaging service formats include: SMS, HTTP, SQS, email
    Can trigger a Lambda function
    Can fanout messages to a large number of recipients (replciate and push messages to multiple endpoints and formats)
    Consumers must subscribe to a topic to receive the notifications

  SES Exam Tip:
    SES is for email only
    SES can send and receive emails
    Not Subscription based
  SNS Exam Tips
    Multiple formats
    Push notifications
    Not for receiving
    Pub/Sub model
    Fanout

Triggering Lambda from Amazon SQS

Kinesis
  What is Kinesis?
    A family of services which enables you to collect, process, and analyze streaming data in real-time.
    Allows you to build custom applications for your own business needs.

  Why Kinesis?
    Kinesis is originally a Greek word, meaning movement or motion.
    Amazon Kinesis deals with data that is in motion, or streaming data.

  Streaming Data?
    Data generated continuously by thousands of data sources, which typically send in the data records simultaneously and in small sizes (kilobytes)
    Financial Transactions
    Stock ProejctionExpression
    Game data (as the gamer plays)
    Social Media feeds
    Location tracking data
    IoT Sensors
    Clickstream data
    Log files

    Often unstructured.

  Four Core Services
    Kinesis Streams: Stream data and video to allow you to build custom applications that process data in real-time
      Data Streams and Video Streams

    Kinesis Data Firehouse: Capture, transform, and load data streams into AWS data stores to enable near-real-time analytics with BI tools.

    Kinesis Data Analytics: Analyze, query, and transform streamed data in real-time using standard SQL. store the results in an AWS data store.

  Kinesis Data Streams
    Producers -> Kinesis Streams (24 hours, max 7 days retention)(Broken down by shards) -> Consumers (EC2, lambda, etc)

    Kinesis Shards
      Kinesis streams are made up of shards
      Each shard is a sequence of one or more data records and provides a fixed unit of capacity
      Five reads per second. The max total read rate is 2 MB per second.
      1000 writes per second. The max total write rate is 1 MB per second.

    The data capacity of the stream is determined by the number of shards.
    If the data rate increases, you can increase capacity on your stream by increasing the number of shards.

    Kinesis Video Streams: Securely stream video from connected devices to AWS
      Videos can be used for analytics and machine learning
  
  Kinesis Data Firehose:
    Producers -> Kinesis Firehose -> (S3 to Redshift) or Elasticsearch
    No shards or streams, no data retention, no EC2 consumers, optional Lambda, 
    BI Tools

  Kinesis Data Analytics
    Producers -> Kinesis Streams and Kinesis FireHose -> Kinesis Analytics to run sql on data -> Redshift, S3, Elasticsearch
    Real-time analytics

  Exam Tips
    Understand the difference between the services

    Streams: capture and store streaming video and data for real-time processing and analysis. Consumer appications process and analyze the data in real-time
    Firehose: Capture, transform, and load data continuously into AWS data store (or other services like Datadog or Splunk). Existing BI applications and tools can be used for near real-time analysis of the stored data.
    Analytics: Real-time analytics using standard SQL on data received by Kinesis Data Streams and Kinesis Data Firehose. Stores in the processed data in AWS data store (S3, Redshift, Elasticsearch)

  Kinesis Stream Demo:
    CloudFormation (solution deployment)    
    EC2 (Producer and Consuemr)
    Kinesis Data Stream (capture streaming data)
    DynamoDB (store the data)

Kinesis Shards vs Consumers
  A Kinesis data stream is a set of shards
  A shard is a sequence of data records in a stream, each data record has a unique sequence number

  Kinesis Recap
    The data capacity of your stream is the sum total capacity of the shards.
    Per Shard:
      5 read transactions, up to a max of 2 MB per second.
      1000 write records per second, up to a max of 1MB per second
    As your data rate increases, you increase the number of shards (resharding).

  What about the consumers?
    Kinesis Client Library runs on the consumer instances.
    Tracks the number of shards in your stream
    Discovers new shards when you reshard.

  Kinesis Client Library
    The KCL ensures that every shard there is a record processer
    Manages the number of record processors relative to the number of shards & consumers.
    If you have only one consumer, the KCL will create all the record processors on a single consumer.
    If you have two consumers, it will load balance and ccreate half the processors on one instance and half on another.

  What about scaling out the consumers?
    With KCL, generall you should ensure that the number of instances does not exceed the number of shards (except for failure or standby puproses)
    You never need multiple instances to handle the processing load of one shard
    However, one worker can process multiple shards

    Its fine if the number of shards exceed the number of instances
    Don't think that just because you reshard, that you need to add more instances
    Instead, CPU utilization is what should drive the quantity of consumer instances you have, NOT the nubmer of shards in your Kinesis stream.
    Use an auto scaling group and base scaling decisions on CPU load on your consumers.

  Exam Tips: Kinesis Shards
    The kinesis client library (KCL) running on your consuemrs creates a record processor for each shard that is being consumed by your instance
    If you increase the number of shards, the KCL will add more record processors on your consumers
    CPU utilization is what you should use to drive the quantity of consumer instnaces you have, NOT the number of shards in your Kinesis stream.
    Use an Auto Scaling group, and base scaling decisions on CPU load on your consumers

Introducing Elastic Beanstalk
  What is Elastic Beanstalk?
    Deploy and Scale web applications without managing or provisioning EC2 instances
    Supported Languages: Java, .NET, PHP, Node.js, Python, Ruby, Go and Docker
    Supported Platforms: Appache http server, tomcat, Nginx, Passenger, and isi
    Focus on writing code, not the underlying infrastructure.

  Provide code to Elastic Beansltak
  Elastic Beanstalk Handles
    1. Infrastructure: Provisioning infrastructure, load balancing, autoscaling, and application health monitoring
    2. Application Platform: Installation and management of the application stack, including patching and updates to your OS and application Platform
    3. You are in control: You ahve complete administrative control of the AWS resources. No additional charges for using Elastic Beanstalk

    Only pay for the resources you create!

  Great for developers!
    Focus on writing code.
    You don't need to worry about any of the underlying infrastructure needed to run the application.
    Get your application to market faster.
    Fastest and simplest way to deploy your application on AWS

  Exam Tips
    Deploy and Scale: Deploys and scales your web applications, including teh web application server platform.
    Programming Languages: Java, PHP, Python, Ruby, Go, Docker, .NET, Node.js
    Application Servers: Appache http server, Tomcat, passenger, Puma, Nginx, and isi
    Provisioend AWS resources: EC2, RDS, Elastic Load Balaners, Auto Scaling groups
    Sytems Administration: OS and application server updates. Monitoring, metrics and health checks are all included.
    Administrative Control: You can fully manage the EC2 instances for you or you can take full adminsitrative control.

Deploying an application with Elastic Beanstalk - Demo
  Overview: 
    PHP -> Elastic Beanstalk -> Provision EC2, Apache http server, security group, load balancer and scaling group

Updating Elastic Beanstalk
  Several Options for Deployment Updates
    All at once: Deploys to all hosts concurrently
    Rolling: Deploys the new version in batches
    Rolling with Additional Batch: Launches an additional batch of instances. Then deploys new version in batches
    Immutable: Deploys the new version to a fresh group of instances before deleting the old instances.
    Traffic Splitting: Installs the new version on a new set of instances, like an immutable deployment. Forwards a percentage of incoming traffic to the new applciation for evaluation.

    All at once: 
      Deploys to all instances simultaneously. 
      You will experience a total outage.\
      Not ideal for mission-critical applciations

      Rolling Back: If the update fails, you need to roll back the changes by redeploying the original version to all your instances. resulting in another outage
      Best for a development or test environment

    Rolling Deployment:
      Deploys the new version in batches
      Each batch is taken out of service while the deployment takes place
      No outage, but capacity will be reduced by the number of instances in a batch while deployment takes place
      Not ideal for performance sensitive systems

    Rolling with additional batch
      Launches additional batch of instances
      Rolling update while maintaining full capacity.
      If updates failes, you need to perform an additional rolling update to roll back the changes

    Immutable (Preferred)
      Deployments cannot be changed. Deploy new version to fresh instances, only when they pass will the old instances be terminated.
      Does not affect the live environment

    Traffic Splitting:
      Enables Canary Testing during deployments
      Installs the new version on a vew set of instances just like an immutable deployment
      Forwards a percentage of incoming client traffic to the new application version for a specified evaluation period
      If the new instances stay healthy, Elastic Beanstalk will forward 100% of the traffic to them and terminate the old ones.

    Exam Tips
      All at Once: Involves a service interruption. Rolling back requires further all at once. Good for testing/dev environments
      Rolling Deployment: Reduced capacity during deployment. Rolling back requires another further rolling update. Not perfomance sensitive applications.
      Rolling with additional batch: Maintains full capacity, rolling back requires a further rolling update.
      Immutable: Maintains full capacity, to roll back delete the new instances. Preferred option for mission critical production systems
      Traffic Splitting: Immutable, but allows for splitting for a canary test.

  Demo: 
  
Advanced Elastic Beanstalk
  Customizing Your Elastic Beanstalk Environment
    You can customize your Elastic Beanstalk environment using Elastic Beanstalk configuration files.

  Configuration: 
    Define packages to Installation
    Create linux users and groups
    Run shell commands
    Enable servicess
    Load Balancer Configuration
  YAML or JSON
  Constraints
    Must have a .config extension
    Must beinside a folder called .ebextensions

  .ebextensions folder
    Must be in the top-level directory
    Source Control    

RDS and Elastic Beanstalk
  Integrating RDS with Elastic Beanstalk
    Elatic Beanstalk supports two ways of integrating an RDS database with your Beanstalk environment.

    Deploying RDS inside your EB environment (DEV or TEST)
      Launch RDS within Elastic Beanstalk Console
      Created within EB environment
      If you terminate the environment, the database will also be terminated
      Good option for Dev and Test deployments, not so good for prod
    Deploying RDS outside your EB environment (PROD)
      Launch RDS outside EB
      Use CLI or RDS console
      It allows you to tear down your application environment without affecting the database instances
      This is the preferred approach for production systems
    
    Connecting to an outside database
      Add an additional security group to environment's auto scaling group to allow EB to communicate with RDS
      Provide connection string information to your application servers using Elastic Beanstalk environment properties.

Other AWS Services Summary
  SQS: Distributed message queueing systems
    Allows us to decouple the componenets of an application so that they are independent
    Pull based, not push based
  
    Standard
      Best-effort ordering
      Message delivered at least once
      Occasional duplicates
      The default queue type

    FIFO
      First in, first out: strictly preserved
      Messages are delivered once
      No duplicates
      Good for banking transactions which need to happen in a strict order
  
    SQS Settings
      Visibility Timeout: The amount of time that the message is invisible in the SQS queue after a reader picks up that message. Default is 30s
        If that task takes >30s, you will need to increase the timout

      Short Polling: A response is returned immediately even if no messages are in the queue. A cost per response.

      Long Polling: Periodically polls the queue and only reutrns a response when a message is in the queue.
        Most cost effective option

      SQS Delay Queue: Postpone delivery of new messages
        Delay perioud: Messages in a delay queue remain invisible for the duration of the delay period
        Distributed applications: Large distributed applications which may need to introduce a delay in processing.

      Large SQS Messages (256 KB - 2 GB)
        Use S3 to store large SQS messages 
        SQS Extended Client Library for Java is needed to manage them
        AWS SDK for Java for S3 operations

  SNS: Simple Notification Service
    Multiple formats: SMS, SQS, HTTP, email
    Push NOtifications only, not for receiving notifications
    Pub/Sub model; consumers must subscribe to a topic
    Fanout: Can fanout messages to a large number of recipients (multiple sqs queues, HTTP endpoints, and email addresses)

  SES: Simple Email Service
    Send and Receive emails
    Not subscription based
    Great for sending automated emails

  SNS vs SQS
  SNS: Messaging service, push based, push notifications
  SQS: Messaging service, pull based, think polling the queue for messages

  Kinesis:
    Understand the difference:
      Streams: Streams and video streams
        Caputre and store streaming video and data for real-time processign and analysis. Consumer applications process and anallyze the data in real-time
        
      Firehose: Capture, transform, and load data continously into AWS data stores or other providers such as datadog or splunk. Existing BI applications and tools can be used for near real-time analysis of the stored data

      Analytics: Real-time analytics using standard SQL on data received by Kinesis Data Streams and Kinesis Data Firehose. Stores the processed data in AWS data stores

    Kinesis Shards: 
      Kinesis streams are made of one or mare shards
      Each shard is a sequence of one or more data records and provides a fixed unit of capacity
      The dat capacity of the stream is determined by the number of shards
      If the data rate increases, you can increase capacity on your stream by increasing the number of shards

      Consuming: 
        Kinesis Client LIbrary running on your consuemrs runs a record processor for each shard being consumed.
        Generally the number of consuemr instances should not exceed the nuumber of shards (except for failover purposes)

        An increase in the number of shards does not mean an increase in consumer. An auto scaling group should scale consumers based on their utilization.

  Elastic Beanstalk
    Deploy and Scale
    Programming Languages: Java, PHP, Python, Ruby, Go, Docker, .NET and Node.js
    Application Servers: Apache HTTP server, Tomcat, passenger, puma, Nginx, and isi
    Provisioned AWS resources
    Systems administration
    Administrative Control: You can take full administrative control

    Elastic Beanstalk Configuration files
      YAML or JSON
      .confix extension
      .ebextensions directory, must be top-level

    Updating an applciation
      All at once (Dev/Test): Involves a service interruption
      Rolling: Reduced capacity
      Rolling with Additional Batch: Maintains full capacity
      Immutable: (Prod) Maintains full capacity, to rollback just delete the new instances
      Traffic Splitting: Allows you to perform canary test

    RDS and EB
      Inside (Dev/Test)
        Quick and easy
        When you terminate, the RDS db is also terminated
      Outside (Prod)
        You can tear down wihtout impacting the database
        Additional configuration steps
          Security Group - EC2 to RDS communication
          Connection Infromation - Think DB connection string